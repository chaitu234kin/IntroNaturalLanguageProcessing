{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA AND CLEAN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\chait\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import udhr\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "nltk.download('udhr')\n",
    "\n",
    "# Language Data\n",
    "english = udhr.raw('English-Latin1')\n",
    "french = udhr.raw('French_Francais-Latin1')\n",
    "italian = udhr.raw('Italian_Italiano-Latin1')\n",
    "spanish = udhr.raw('Spanish_Espanol-Latin1') \n",
    "\n",
    "# Training and Development Data\n",
    "english_train, english_dev = english[0:1000], english[1000:1100]\n",
    "french_train, french_dev = french[0:1000], french[1000:1100]\n",
    "italian_train, italian_dev = italian[0:1000], italian[1000:1100]\n",
    "spanish_train, spanish_dev = spanish[0:1000], spanish[1000:1100] \n",
    "\n",
    "def CleanData(raw_tokens):\n",
    "    return [token.lower() for token in raw_tokens if token.isalpha()]\n",
    "\n",
    "#Testing Data\n",
    "english_test = udhr.words('English-Latin1')[0:1000]\n",
    "french_test = udhr.words('French_Francais-Latin1')[0:1000]\n",
    "italian_test = udhr.words('Italian_Italiano-Latin1')[0:1000]\n",
    "spanish_test = udhr.words('Spanish_Espanol-Latin1')[0:1000]\n",
    "\n",
    "english_test_clean = CleanData(english_test)\n",
    "french_test_clean = CleanData(french_test)\n",
    "italian_test_clean = CleanData(italian_test)\n",
    "spanish_test_clean = CleanData(spanish_test)\n",
    "\n",
    "# Training Data \n",
    "english_train_clean = CleanData(nltk.word_tokenize(english_train))\n",
    "french_train_clean = CleanData(nltk.word_tokenize(french_train))\n",
    "spanish_train_clean = CleanData(nltk.word_tokenize(spanish_train))\n",
    "italian_train_clean = CleanData(nltk.word_tokenize(italian_train))\n",
    "\n",
    "english_train_clean_rawtext = ' '.join(english_train_clean)\n",
    "french_train_clean_rawtext = ' '.join(french_train_clean)\n",
    "spanish_train_clean_rawtext = ' '.join(spanish_train_clean)\n",
    "italian_train_clean_rawtext = ' '.join(italian_train_clean)\n",
    "# Dev Data\n",
    "english_dev_clean = CleanData(nltk.word_tokenize(english_dev))\n",
    "french_dev_clean = CleanData(nltk.word_tokenize(french_dev))\n",
    "spanish_dev_clean = CleanData(nltk.word_tokenize(spanish_dev))\n",
    "italian_dev_clean = CleanData(nltk.word_tokenize(italian_dev))\n",
    "\n",
    "english_dev_clean_rawtext = ' '.join(english_dev_clean)\n",
    "french_dev_clean_rawtext = ' '.join(french_dev_clean)\n",
    "spanish_dev_clean_rawtext = ' '.join(spanish_dev_clean)\n",
    "italian_dev_clean_rawtext = ' '.join(italian_dev_clean)\n",
    "\n",
    "\n",
    "def generate_NGrams_Character(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "\n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "\n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s if token != \"\"]\n",
    "\n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\"\".join(ngram) for ngram in ngrams]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIGRAM MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Unigram Models for English against English and French models \n",
      "English Unigram Probability is 63.48\n"
     ]
    }
   ],
   "source": [
    "print('Testing Unigram Models for English against English and French models ')\n",
    "def Build_Unigram_Model(language):\n",
    "    raw_text = ''\n",
    "    if language == 'english':\n",
    "        raw_text = generate_NGrams_Character(english_train_clean_rawtext + english_dev_clean_rawtext, 1)\n",
    "    elif language == 'spanish':\n",
    "        raw_text = generate_NGrams_Character(spanish_train_clean_rawtext + spanish_dev_clean_rawtext, 1)\n",
    "    elif language == 'french':\n",
    "        raw_text = generate_NGrams_Character(french_train_clean_rawtext + french_dev_clean_rawtext, 1)\n",
    "    elif language == 'italian':\n",
    "        raw_text = generate_NGrams_Character(italian_train_clean_rawtext + italian_dev_clean_rawtext, 1)\n",
    "    unigrams = raw_text\n",
    "    unigram_model = nltk.FreqDist(unigrams)\n",
    "    return unigram_model\n",
    "    \n",
    "unigram_model_english = Build_Unigram_Model('english')    \n",
    "unigram_model_spanish = Build_Unigram_Model('spanish')\n",
    "unigram_model_italian = Build_Unigram_Model('italian')\n",
    "unigram_model_french = Build_Unigram_Model('french')\n",
    "\n",
    "def calculate_unigram_probability_model(word, language):\n",
    "    model = None\n",
    "    probability = 1\n",
    "    \n",
    "    if language == 'english':\n",
    "        model = unigram_model_english\n",
    "    elif language == 'spanish':\n",
    "        model = unigram_model_spanish\n",
    "    elif language == 'french':\n",
    "        model = unigram_model_french\n",
    "    elif language == 'italian':\n",
    "        model = unigram_model_italian\n",
    "        \n",
    "    for character in word: \n",
    "        probability = (probability * model.freq(character))\n",
    "    return probability\n",
    "        \n",
    "def Test_Unigram_Models(Test_data_set):\n",
    "    Total_english_probability = -1\n",
    "    Total_spanish_probability = -1\n",
    "    Total_italian_probability = -1\n",
    "    Total_french_probability = -1\n",
    "    \n",
    "    for each_word in Test_data_set:\n",
    "        english_probability= calculate_unigram_probability_model(each_word, 'english')\n",
    "        spanish_probability= calculate_unigram_probability_model(each_word, 'spanish')\n",
    "        french_probability= calculate_unigram_probability_model(each_word, 'french')\n",
    "        italian_probability= calculate_unigram_probability_model(each_word, 'italian')\n",
    "        \n",
    "        Total_english_probability  = Total_english_probability + english_probability\n",
    "        Total_spanish_probability  = Total_spanish_probability + spanish_probability\n",
    "        Total_italian_probability  = Total_italian_probability + italian_probability\n",
    "        Total_french_probability  = Total_french_probability + french_probability\n",
    "    \n",
    "    if(Total_english_probability > Total_french_probability):\n",
    "        print('English Unigram Probability is', round(Total_english_probability*100,2))\n",
    "    else:\n",
    "        print('French Unigram Probability is', round(Total_french_probability*100,2))\n",
    "\n",
    "\n",
    "Test_Unigram_Models(english_test_clean)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIGRAM MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Bigram Probability is 63.170820576352774\n"
     ]
    }
   ],
   "source": [
    "def Build_BigramModel(language):\n",
    "    Bi_gram_Model = ConditionalFreqDist()\n",
    "    Bi_grams = ''\n",
    "    if language == 'english':\n",
    "        Bi_grams = generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 2)\n",
    "    elif language == 'spanish':\n",
    "        Bi_grams = generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 2)\n",
    "    elif language == 'french':\n",
    "        Bi_grams = generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 2)\n",
    "    elif language == 'italian':\n",
    "        Bi_grams = generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 2)\n",
    "    for bigram in Bi_grams:\n",
    "        Bi_gram_Model[bigram[0]][bigram[1]]+=1\n",
    "    return Bi_gram_Model\n",
    "\n",
    "Bi_gram_model_english = Build_BigramModel('english')\n",
    "Bi_gram_model_spanish = Build_BigramModel('spanish')\n",
    "Bi_gram_model_french = Build_BigramModel('french')\n",
    "Bi_gram_model_italian = Build_BigramModel('italian')\n",
    "\n",
    "def calculate_bigram_probability_model(word, language):\n",
    "    bigram_model = None\n",
    "    unigram_model = None\n",
    "    probability = 1\n",
    "    bigram_count = 0\n",
    "    unigram_count = 0\n",
    "    \n",
    "    if language == 'english':\n",
    "        bigram_model = Bi_gram_model_english\n",
    "        unigram_model = unigram_model_english\n",
    "        bigram_count =  len(generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 2))\n",
    "        unigram_count =  len(generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 1))\n",
    "    elif language == 'spanish':\n",
    "        bigram_model = Bi_gram_model_spanish\n",
    "        unigram_model = unigram_model_spanish\n",
    "        bigram_count = len(generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 2))\n",
    "        unigram_count =  len(generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 1))\n",
    "    elif language == 'french':\n",
    "        bigram_model = Bi_gram_model_french\n",
    "        unigram_model = unigram_model_french\n",
    "        bigram_count = len(generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 2))\n",
    "        unigram_count =  len(generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 1))\n",
    "    elif language == 'italian':\n",
    "        bigram_model = Bi_gram_model_italian\n",
    "        unigram_model = unigram_model_italian\n",
    "        bigram_count  = len(generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 2))\n",
    "        unigram_count =  len(generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 1))\n",
    "            \n",
    "    for bigrams_of_word in generate_NGrams_Character(word,2):\n",
    "        numerator_probability = (bigram_model[bigrams_of_word[0]][bigrams_of_word[1]] + 1)/ (bigram_count + len(bigram_model))\n",
    "        ## Add One Smoothing. \n",
    "        denominator_probability = (unigram_model[bigrams_of_word[0]] + 1)/( len(unigram_model) + unigram_count)\n",
    "        probability = probability * (numerator_probability/denominator_probability)\n",
    "    return probability\n",
    "\n",
    "def Test_bigram_Models(Test_data_set):\n",
    "    Total_english_probability = 0\n",
    "    Total_spanish_probability = 0\n",
    "    Total_italian_probability = 0\n",
    "    Total_french_probability = 0\n",
    "    \n",
    "    for each_word in Test_data_set:\n",
    "        english_probability= calculate_bigram_probability_model(each_word, 'english')\n",
    "        spanish_probability= calculate_bigram_probability_model(each_word, 'spanish')\n",
    "        french_probability= calculate_bigram_probability_model(each_word, 'french')\n",
    "        italian_probability= calculate_bigram_probability_model(each_word, 'italian')\n",
    "        \n",
    "                \n",
    "        Total_english_probability  = Total_english_probability + english_probability\n",
    "        Total_spanish_probability  = Total_spanish_probability + spanish_probability\n",
    "        Total_italian_probability  = Total_italian_probability + italian_probability\n",
    "        Total_french_probability  = Total_french_probability + french_probability\n",
    "    if (Total_english_probability > Total_french_probability):\n",
    "        print('English Bigram Probability is', Total_english_probability)\n",
    "    else:\n",
    "        print('French Bigram Probability is', Total_french_probability)\n",
    "    \n",
    "Test_bigram_Models(english_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIGRAM MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Trigram Probability is 64.20014204506471\n"
     ]
    }
   ],
   "source": [
    "def Build_TrigramModel(language):\n",
    "    tri_gram_Model = ConditionalFreqDist()\n",
    "    trigrams = ''\n",
    "    \n",
    "    if language == 'english':\n",
    "        trigrams = generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 3)\n",
    "    elif language == 'spanish':\n",
    "        trigrams = generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 3)\n",
    "    elif language == 'french':\n",
    "        trigrams = generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 3)\n",
    "    elif language == 'italian':\n",
    "        trigrams = generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 3)\n",
    "        \n",
    "    for trigram in trigrams:\n",
    "        tri_gram_Model[trigram[:2]][trigram[2]]+=1\n",
    "    return tri_gram_Model\n",
    "\n",
    "trigram_model_english = Build_TrigramModel('english')\n",
    "trigram_model_spanish = Build_TrigramModel('spanish')\n",
    "trigram_model_french = Build_TrigramModel('french')\n",
    "trigram_model_italian = Build_TrigramModel('italian')\n",
    "\n",
    "def calculate_Trigram_probability_model(word, language):\n",
    "    trigram_model  = None\n",
    "    bigram_model = None\n",
    "    probability = 1\n",
    "    bigram_count = 0\n",
    "    trigram_count = 0\n",
    "    \n",
    "    if language == 'english':\n",
    "        trigram_model = trigram_model_english\n",
    "        bigram_model = Bi_gram_model_english\n",
    "        bigram_count =  len(generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 2))\n",
    "        trigram_count = len(generate_NGrams_Character(' '+english_train_clean_rawtext + english_dev_clean_rawtext+' ', 3))\n",
    "    elif language == 'spanish':\n",
    "        trigram_model = trigram_model_spanish\n",
    "        bigram_model = Bi_gram_model_spanish\n",
    "        bigram_count =  len(generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 2))\n",
    "        trigram_count = len(generate_NGrams_Character(' '+spanish_train_clean_rawtext + spanish_dev_clean_rawtext+' ', 3))\n",
    "    elif language == 'french':\n",
    "        trigram_model = trigram_model_french\n",
    "        bigram_model = Bi_gram_model_french\n",
    "        bigram_count =  len(generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 2))\n",
    "        trigram_count = len(generate_NGrams_Character(' '+french_train_clean_rawtext + french_dev_clean_rawtext+' ', 3))\n",
    "    elif language == 'italian':\n",
    "        trigram_model = trigram_model_italian\n",
    "        bigram_model = Bi_gram_model_italian\n",
    "        bigram_count =  len(generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 2))\n",
    "        trigram_count = len(generate_NGrams_Character(' '+italian_train_clean_rawtext + italian_dev_clean_rawtext+' ', 3))\n",
    "        \n",
    "    for trigrams_of_word in generate_NGrams_Character(word,3):\n",
    "        ## Add one Smoothing\n",
    "        numerator_probability = (trigram_model[trigrams_of_word[:2]][trigrams_of_word[2]] + 1) / (trigram_count + len(trigram_model))\n",
    "        denominator_probability = (bigram_model[trigrams_of_word[0]][trigrams_of_word[1]] + 1) / (bigram_count + len(bigram_model))\n",
    "        probability = probability * (numerator_probability/denominator_probability)\n",
    "    return probability\n",
    "\n",
    "def Test_Trigram_Models(Test_data_set):\n",
    "    Total_english_probability = 0\n",
    "    Total_spanish_probability = 0\n",
    "    Total_italian_probability = 0\n",
    "    Total_french_probability = 0\n",
    "    \n",
    "    for each_word in Test_data_set:\n",
    "        english_probability= calculate_Trigram_probability_model(each_word, 'english')\n",
    "        spanish_probability= calculate_Trigram_probability_model(each_word, 'spanish')\n",
    "        french_probability= calculate_Trigram_probability_model(each_word, 'french')\n",
    "        italian_probability= calculate_Trigram_probability_model(each_word, 'italian')\n",
    "        \n",
    "        Total_english_probability  = Total_english_probability + english_probability\n",
    "        Total_spanish_probability  = Total_spanish_probability + spanish_probability\n",
    "        Total_italian_probability  = Total_italian_probability + italian_probability\n",
    "        Total_french_probability  = Total_french_probability + french_probability\n",
    "        Normalized_english_probability = ((Total_english_probability*2)/10)\n",
    "        Normalized_spanish_probability = ((Total_spanish_probability*2)/10)\n",
    "        Normalized_italian_probability =  ((Total_italian_probability*2)/10)\n",
    "        Normalized_french_probability =  ((Total_french_probability*2)/10)\n",
    "    if (Normalized_english_probability > Normalized_french_probability):\n",
    "        print('English Trigram Probability is', (Normalized_english_probability))\n",
    "    else:\n",
    "         print('French Trigram Probability is', (Normalized_french_probability))\n",
    "\n",
    "Test_Trigram_Models(english_test_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGLISH VS FRENCH\n",
    "   ### All The Above Data Set has been cleaned, pre-processed, converted to lower case words, Applied Add One Laplace Smoothing Technique and  processed. When English test data has been tested on English vs French Trigram, it has been found that english had 64 % accuracy and French had 60 %.  English trigram is more accurate than French.  When tested against English vs French Bi-gram , English outperformed french bi-gram, English bigram reported accuracy of 63 % and French reported accuracy of 29%. When performed against English vs French unigram. English Unigram was more accurate than French, showing 63 % accuracy.\n",
    "   ### English Trigram - 64 % \n",
    "   ### English Bigram - 63% \n",
    "   ### English Unigram 63% \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish VS Italian\n",
    "   ### All The Above Data Set has been cleaned, pre-processed, converted to lower case words, Applied Add One Laplace Smoothing Technique and  processed. When Spanish test data has been tested on Spanish vs Italian Trigram, it has been found that spanish had 72 % accuracy and italian had  69 %.  Spanish trigram is more accurate than italian.  When tested against Spanish vs Italian Bi-gram , Spanish outperformed Italian bi-gram, Spanish bigram reported accuracy of 64 % and Italian reported accuracy of 41%. When performed against Spanish vs Italian unigram. Spanish Unigram was more accurate than Italian, showing 51% accuracy whereas Italian unigram showed 42%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
